---
permalink: /
title: "Bingliang Li"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<style>
table {
    border-collapse: collapse;
}
table, th, td {
   border: none;
   font-size: 18px;
}
blockquote {
    border-left: none;
    padding-left: 10px;
}
</style>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
Hello there! I am Bingliang Li. <s>If everything goes with the plan</s>, I will start my PhD journey at the University of New South Wales in <s>late 2025</s> early 2026, co-supervised by these legends: [Dr Huadong Mo](https://www.unsw.edu.au/staff/huadong-mo), [Dr Dong Gong](https://www.unsw.edu.au/staff/dong-gong) (Joint), [Professor Daoyi Dong](https://eng.anu.edu.au/people/daoyi-dong/) (Secondary), [Dr Yawen Chen](https://www.unsw.edu.au/staff/wendy-chen) (Secondary). Previously, I obtained my master's degree from The Chinese University of Hong Kong, Shenzhen, supervised by [Professor Ruimao Zhang](http://www.zhangruimao.site/)üëç, and a bachelor's degree from Lanzhou University. I also worked as an Algorithm Engineer at Xiaomi AI Lab.

Currently, my research focuses on open-world multimodal perception and generation, including image, audio, video, and more. My long-term research goal is to build an interactive system for high-quality video generation and editing. You are welcome to contact me via Email! bing.liang.li[at]outlook[dot]com

# News

- Tri-Ergon is accepted to AAAI 2025, work done at vivo.
- Two papers accepted to CVPR 2024!
- One paper accepted to ACM MM 2023.

# Publications

[**Tri-Ergon: Fine-grained Video-to-Audio Generation with Multi-modal Conditions and LUFS Control**](https://arxiv.org/abs/2412.20378)<br />
**Bingliang Li**, Fengyu Yang, Yuxin Mao, Qingwen Ye, Hongkai Chen, Yiran Zhong<br />
AAAI Conference on Artificial Intelligence ( **AAAI** ), 2025

[**Open-World Human-Object Interaction Detection via Multi-modal Prompts**](https://arxiv.org/abs/2406.07221)<br />
Jie Yang\* , **Bingliang Li**\*, Ailing Zeng, Lei Zhang, Ruimao Zhang<br />
IEEE Conference on Computer Vision and Pattern Recognition ( **CVPR** ), 2024

[**FreeMan: Towards Benchmarking 3D Human Pose Estimation under Real-World Conditions**](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_FreeMan_Towards_Benchmarking_3D_Human_Pose_Estimation_under_Real-World_Conditions_CVPR_2024_paper.pdf)<br />
Jiong Wang\*, Fengyu Yang\*, **Bingliang Li**, Wenbo Gou, Danqi Yan, Ailing Zeng, Yijun Gao, Junle Wang, Yanqing Jing, Ruimao Zhang<br />
IEEE Conference on Computer Vision and Pattern Recognition ( **CVPR** ), 2024

[**Dance with You: The Diversity Controllable Dancer Generation via Diffusion Models**](https://arxiv.org/abs/2308.13551)<br />
Siyue Yao, Mingjie Sun, **Bingliang Li**, Fengyu Yang, Junle Wang, Ruimao Zhang<br />
ACM Multimedia ( **ACM MM** ), 2023

# Experiences

vivo | Research Intern | 2023 - 2024
Xiaomi AI Lab | Algorithm Engineer | 2024 - 2025

# Academic Activity

Reviewer for Conferences:

1. Neural Information Processing Systems (NeurIPS) -- 2025
2. ACM Multimedia (ACM MM) -- 2023, 2024, 2025

<script type='text/javascript' id='mapmyvisitors' src='https://mapmyvisitors.com/map.js?cl=080808&w=300&t=tt&d=vqpfuHPN4SRXJYZrsJjwPsNqPT96rfjntKKjp42hh_4&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>